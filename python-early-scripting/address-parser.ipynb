{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from address_parser import Parser\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import csv\n",
    "from IPython.display import clear_output\n",
    "import usaddress\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "#creating functions to parse addresses\n",
    "\n",
    "\n",
    "# this function creates a new database and failure log but wont overwrite existing one\n",
    "def create_dataframe(database_name, header):\n",
    "    if path.exists(database_name):\n",
    "        print('CSV already exists.')\n",
    "    else:\n",
    "        with open(database_name, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(header)\n",
    "        print('New CSV created.')\n",
    "        \n",
    "# this function converts an OrderedDict into a Pandas dataframe\n",
    "def convert_ord_dict(ordered_dict):\n",
    "    keys = list(ordered_dict[0].keys())\n",
    "    values = list(ordered_dict[0].values())\n",
    "    df1 = pd.DataFrame(keys).transpose()\n",
    "    df2 = pd.DataFrame(values).transpose()\n",
    "    df3 = df1.append(df2)\n",
    "    new_header1 = df3.iloc[0] #grab the first row for the header\n",
    "    df3.reset_index()\n",
    "    df3.columns = new_header1 #set the header row as the df header\n",
    "    df3 = df3.iloc[[1]]\n",
    "    return df3\n",
    "\n",
    "# this function converts a dict into a Pandas dataframe\n",
    "def convert_dict(dict):\n",
    "    df1 = pd.DataFrame(dict).transpose()\n",
    "    new_header1 = df1.iloc[1]\n",
    "    df1.reset_index()\n",
    "    df1.columns = new_header1 #set the header row as the df header\n",
    "    df1 = df1.iloc[[0]]\n",
    "    return df1\n",
    "\n",
    "# this function wipes the extra information from a str when calling a position in a pandas dataframe\n",
    "def clear_pandas_format(variable):\n",
    "    variable = variable.split('0    ')[1].split('Name:')[0].strip()\n",
    "    return variable\n",
    "\n",
    "# this is the entrypoint function, input is a dataframe with required columns 'defendant_address' and 'case_number', output is the name of the dataframe with parsed addresses\n",
    "def howard_address_parse(input, output):\n",
    "    \n",
    "    #failures is a list of errors\n",
    "    global failures\n",
    "    failures = list()\n",
    "    \n",
    "    #reading input dataframe\n",
    "    input_table = pd.read_csv(input)\n",
    "    \n",
    "    #creating output dataframe\n",
    "    create_dataframe(output, ['case_number', 'address_number', 'street', 'city', 'state', 'zipcode', 'occupancy_type', 'occupancy_identifier', 'street_name', 'street_type', 'street_directional', 'unparsed_address'])\n",
    "    \n",
    "    #defining parser\n",
    "    parser = Parser()\n",
    "    \n",
    "    #looping through defendant_address column in input\n",
    "    for enum, i in enumerate(input_table.defendant_address):\n",
    "        \n",
    "        # report position in loop, number of errors\n",
    "        print(\"Starting \" +  str(enum + 1) + \". \" + str(len(input_table.defendant_address)-(enum + 1)) + \" remain. There have been \" + str(len(failures)) + \" errors.\" )\n",
    "\n",
    "        # assign case number based on input\n",
    "        case_number = input_table.case_number[enum]\n",
    "        unparsed_address = i\n",
    "        \n",
    "        \n",
    "        ###This code fixes formating in addresses that improve accuracy of this parse and geocoding\n",
    "        \n",
    "        #st. in st. petersburg causes errors, replacing st. and st with saint if it comes next petersburg\n",
    "        parse_start = str(i).replace('st petersburg', 'saint peterburg').replace('st. petersburg', 'saint peterburg').replace('-', ' ')\n",
    "        \n",
    "        # removing any characters inside parentheses\n",
    "        try:\n",
    "            first_half = parse_start.split('(')[0].strip()\n",
    "            second_half = parse_start.split(')')[1].strip()\n",
    "            parse_ready = (first_half + second_half)\n",
    "        except:\n",
    "            parse_ready = parse_start\n",
    "\n",
    "        # parse address\n",
    "        try:\n",
    "            # tries to use more complete tag parsing, if that fails, uses less-featured .parse\n",
    "            try:\n",
    "                #parsing address, converting output from an OrderedDict to a Pandas dataframe called temp\n",
    "                temp = convert_ord_dict(usaddress.tag(parse_ready))\n",
    "            except:\n",
    "                #if .tag fails, use the less specific .parse\n",
    "                temp = convert_dict(usaddress.parse(parse_ready))\n",
    "\n",
    "            # converting information from Pandas dataframe to cleaned Python objects\n",
    "            try:\n",
    "                address_number = clear_pandas_format(str(temp.AddressNumber))\n",
    "            except:\n",
    "                address_number = None\n",
    "            \n",
    "\n",
    "            try:\n",
    "                street_name = clear_pandas_format(str(temp.StreetName))\n",
    "            except:\n",
    "                street_name = None              \n",
    "            \n",
    "            \n",
    "            #test if street_name is only a number, adds suffix if needed\n",
    "            # this change improves accuracy\n",
    "            try:\n",
    "                #see if streetname is just a number\n",
    "                int(street_name)\n",
    "                #if it is, create a suffix to attach based on the last digit\n",
    "                if street_name[-1] == '1':\n",
    "                    suffix = 'st'\n",
    "                elif street_name[-1] == '2':\n",
    "                    suffix = 'nd'\n",
    "                elif street_name[-1] == '3':\n",
    "                    suffix = 'rd'\n",
    "                else:\n",
    "                    suffix = 'th'\n",
    "                #append the suffix\n",
    "                street_name = (str(street_name) + suffix)\n",
    "            except:\n",
    "                #if it is not only a number, pass\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                occupancy_type = clear_pandas_format(str(temp.OccupancyType))\n",
    "            except:\n",
    "                occupancy_type = None                      \n",
    "            \n",
    "\n",
    "            try:\n",
    "                occupancy_identifier = clear_pandas_format(str(temp.OccupancyIdentifier)).replace(' ', '')\n",
    "            except:\n",
    "                occupancy_identifier = None                      \n",
    "            \n",
    "\n",
    "            try:\n",
    "                city = clear_pandas_format(str(temp.PlaceName))\n",
    "            except:\n",
    "                city = None                      \n",
    "            \n",
    "\n",
    "            try:\n",
    "                state = clear_pandas_format(str(temp.StateName))\n",
    "            except:\n",
    "                state = None                      \n",
    "            \n",
    "\n",
    "            try:\n",
    "                zipcode = clear_pandas_format(str(temp.ZipCode))\n",
    "            except:\n",
    "                zipcode = None                      \n",
    "            \n",
    "\n",
    "            # street_type and street_directional can be output in pre and post, accomodating for both locations\n",
    "            try:\n",
    "                street_type_post = clear_pandas_format(str(temp.StreetNamePostType))\n",
    "                street_type = street_type_post\n",
    "            except:\n",
    "                street_type_post = None\n",
    "                \n",
    "            try:\n",
    "                street_type_pre = clear_pandas_format(str(temp.StreetNamePreType))\n",
    "                street_type = street_type_pre\n",
    "            except:\n",
    "                street_type_pre = None\n",
    "                \n",
    "            try:\n",
    "                street_type\n",
    "            except:\n",
    "                street_type = None\n",
    "\n",
    "            try:\n",
    "                street_directional_pre = clear_pandas_format(str(temp.StreetNamePreDirectional))\n",
    "                street_directional = street_directional_pre\n",
    "            except:\n",
    "                street_directional_pre = None\n",
    "                \n",
    "            try:\n",
    "                street_directional_post = clear_pandas_format(str(temp.StreetNamePostDirectional))\n",
    "                street_directional = street_directional_post\n",
    "            except:\n",
    "                street_directional_post = None\n",
    "            \n",
    "            try:\n",
    "                street_directional\n",
    "            except:\n",
    "                street_directional = None\n",
    "            \n",
    "            #this function builds a street address from the individual parsed parts\n",
    "            #doing this removes superflous info and generally improves succesful geocodes\n",
    "            street = (str(address_number) + ' ' + str(street_directional_pre) + ' ' + str(street_type_pre)  + ' ' + str(street_name) + ' ' + str(street_type_post) + ' ' + str(street_directional_post)).replace('None', '').replace(',', '').replace('  ', ' ')\n",
    "    \n",
    "        \n",
    "        except:\n",
    "            \n",
    "            #writing nones if loop breaks\n",
    "            address_number = None\n",
    "            street_name = None\n",
    "            occupancy_type = None\n",
    "            occupancy_identifier = None\n",
    "            street = None\n",
    "            city = None\n",
    "            state = None\n",
    "            zipcode = None\n",
    "            street_type = None\n",
    "            street_directional = None\n",
    "            failures.append(enum)\n",
    "\n",
    "        #write data to output dataframe    \n",
    "        with open(output, 'a', newline='') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=',')\n",
    "            data_out = [case_number, address_number, street, city, state, zipcode, occupancy_type, occupancy_identifier, street_name, street_type, street_directional, unparsed_address]\n",
    "            writer.writerow(data_out)\n",
    "        \n",
    "        #this clears the output in the terminal after every loop\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE LOG ####\n",
    "#remove commas before placename\n",
    "    # add code to replace commas with nothing\n",
    "    \n",
    "#remove anything between parentheses\n",
    "    # added code the splits before parens and after parents in two halves and puts together\n",
    "    # would break if their is multiple parentheses\n",
    "    \n",
    "#fix pre/post positional street direction\n",
    "    # created pre and post for the purposes of creating the street address, still not assigning pre or post into dataframe\n",
    "\n",
    "#add a th if a street name is just digits and does not have it\n",
    "    # creating function that tests if int, then appends suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8167. 0 remain. There have been 0 errors.\n"
     ]
    }
   ],
   "source": [
    "howard_address_parse('./input/fl_pinellas_clean.csv', './output/fl_pinellas_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 15195. 0 remain. There have been 0 errors.\n"
     ]
    }
   ],
   "source": [
    "howard_address_parse('./input/fl_hills_clean.csv', './output/fl_hills_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 45070. 0 remain. There have been 0 errors.\n"
     ]
    }
   ],
   "source": [
    "howard_address_parse('./input/ga_dekalb_clean.csv', './output/ga_dekalb_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 57956. 0 remain. There have been 0 errors.\n"
     ]
    }
   ],
   "source": [
    "howard_address_parse('./input/ga_fulton_clean.csv', './output/ga_fulton_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 36410. 0 remain. There have been 0 errors.\n"
     ]
    }
   ],
   "source": [
    "howard_address_parse('./input/tn_shelby_clean.csv', './output/tn_shelby_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 19423. 0 remain. There have been 0 errors.\n"
     ]
    }
   ],
   "source": [
    "howard_address_parse('./input/wi_milw_clean.csv', './output/wi_milw_parsed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
