{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the variable inputs you must input to operate the scraper\n",
    "#input username and password\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "#write the path of your chrome driver here, in quotes; directory must identify the file by name\n",
    "executable_path = \"chromedriver.exe\"\n",
    "#write the path to the folder you want to download into here, in quotes\n",
    "download_path = \"C:\\\\Users\\\\rlitt\\Downloads\\\\tulsa\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import JavascriptException, NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException\n",
    "from selenium.common.exceptions import ElementNotInteractableException, ElementNotSelectableException\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from IPython.display import clear_output\n",
    "from selenium.common.exceptions import ElementNotInteractableException, ElementNotSelectableException\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import unicodedata\n",
    "from os import path\n",
    "import csv\n",
    "\n",
    "\n",
    "# this function lowers the case, strips blanks and removes linebreaks\n",
    "def clean(str):\n",
    "    str = str.lower()\n",
    "    str = str.strip()\n",
    "    str = str.replace('\\n', ' ')\n",
    "    return str\n",
    "\n",
    "def try_assign(xpath):\n",
    "    try:\n",
    "        info = clean(driver.find_element_by_xpath(xpath).text)\n",
    "    except:\n",
    "        info = 'none'\n",
    "    return info\n",
    "\n",
    "def get_date(string):\n",
    "    if string != 'none':\n",
    "        string = string[0:10]\n",
    "    else:\n",
    "        string = 'none'\n",
    "    return string\n",
    "\n",
    "# this function writes multiples 'none's to a given list until that list is 3 items long\n",
    "def parse_party_list(list):\n",
    "    try:\n",
    "        list\n",
    "        if len(list) >= 3:\n",
    "            pass\n",
    "        elif len(list) == 2:\n",
    "            list.append('none')\n",
    "        elif len(list) == 1:\n",
    "            list.append('none')\n",
    "            list.append('none')\n",
    "        else:\n",
    "            list = ['none', 'none', 'none']\n",
    "    except:\n",
    "        list = ['none', 'none', 'none']\n",
    "    return list\n",
    "\n",
    "def more_than_three(party):\n",
    "    if len(party) > 3:\n",
    "        output = 'yes'\n",
    "        return output\n",
    "    else:\n",
    "        output = 'no'\n",
    "        return output\n",
    "\n",
    "def create_dataframe(database_name, header):\n",
    "    if path.exists(database_name):\n",
    "        print('CSV already exists.')\n",
    "    else:\n",
    "        with open(database_name, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(header)\n",
    "        print('New CSV created.')\n",
    "\n",
    "def create_failure_log(failure_name):\n",
    "    #create blank log for failures\n",
    "    if path.exists(failure_name):\n",
    "        print('Failure text exists.')\n",
    "    else:\n",
    "        with open(failure_name, 'w') as outfile:\n",
    "                writer = csv.writer(outfile)\n",
    "        print('Failure text created.')\n",
    "\n",
    "def parse_string(text, str1, str2):\n",
    "    try:\n",
    "        parse = text.split(str1)\n",
    "        parse = parse[1].split(str2)\n",
    "        parse = clean(parse[0])\n",
    "    except:\n",
    "        parse = 'none'\n",
    "    return parse\n",
    "\n",
    "def does_string_appear(string_to_search_in, text_to_find):\n",
    "    test = string_to_search_in.find(text_to_find)\n",
    "    if test != -1:\n",
    "        output = 'yes'\n",
    "    else:\n",
    "        output = 'no'\n",
    "    return output\n",
    "\n",
    "class oklahoma():\n",
    "\n",
    "    def load_new_driver(county_input, headless='no'):\n",
    "        global driver, county, short_timeout, long_timeout\n",
    "\n",
    "        #wait to load until\n",
    "        short_timeout = 5\n",
    "        long_timeout = 60\n",
    "        county = county_input\n",
    "\n",
    "        #try to close an existing driver\n",
    "        try:\n",
    "            driver.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        chrome_options = Options()\n",
    "        #load headless given input\n",
    "        if str(headless) == 'headless':\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "        else:\n",
    "            pass\n",
    "        chrome_options.add_argument(\"--window-size=1920x700\")\n",
    "        chrome_options.add_argument(\"--disable-notifications\")\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--verbose')\n",
    "        chrome_options.add_experimental_option(\"prefs\", {\n",
    "                \"download.default_directory\": download_path,\n",
    "                \"download.prompt_for_download\": False,\n",
    "                \"download.directory_upgrade\": True,\n",
    "                \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "                \"safebrowsing.enabled\": False\n",
    "                })\n",
    "        driver = webdriver.Chrome(options=chrome_options, executable_path=executable_path)\n",
    "        driver.get('https://www.oscn.net/dockets/')\n",
    "        #wait for page to load\n",
    "        WebDriverWait(driver, long_timeout).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//div[@id=\"oscn-content\"]')))\n",
    "\n",
    "    def create_case_list(start, end, year, county):\n",
    "        global case_list\n",
    "        case_list = list()\n",
    "        prefix = \"https://www.oscn.net/dockets/GetCaseInformation.aspx?db=\"\n",
    "        suffix = \"&number=\"\n",
    "        for i in range(start, end):\n",
    "            case_number = (prefix + str(county) + suffix + 'sc-' + str(year) + '-' + str(i))\n",
    "            case_list.append(case_number)\n",
    "\n",
    "    def parse_parties(second_split):\n",
    "        global party_output\n",
    "        plaintiff_list = list()\n",
    "        defendant_list = list()\n",
    "\n",
    "        # pull parties info and split into a list using the \"v.\"\n",
    "        try:\n",
    "            parties = driver.find_element_by_xpath('//table[@class=\"caseStyle\"]/tbody/tr/td').text.split('v.')\n",
    "            # try to split plaintiff using \"and\"\n",
    "            try:\n",
    "                plaintiff = parties[0].split(second_split)\n",
    "                for i in plaintiff:\n",
    "                    plaintiff_list.append(clean(i.replace('Plaintiff', '').replace(',', '').replace('.', '')))\n",
    "            except:\n",
    "                plaintiff = 'none'\n",
    "\n",
    "            # try to split plaintiff using \"and\"\n",
    "            try:\n",
    "                defendant = parties[1].split(second_split)\n",
    "                for i in defendant:\n",
    "                    defendant_list.append(clean(i.replace('Defendant', '').replace(',', '').replace('.', '')))\n",
    "            except:\n",
    "                defendant = 'none'\n",
    "        except:\n",
    "            plaintiff = 'none'\n",
    "            defendant = 'none'\n",
    "\n",
    "        # parse lists to ensure a len of 3\n",
    "        parse_party_list(plaintiff_list)\n",
    "        parse_party_list(defendant_list)\n",
    "        plaintiff_more_than_three = more_than_three(plaintiff_list)\n",
    "        defendant_more_than_three = more_than_three(defendant_list)\n",
    "        party_output = [*plaintiff_list, plaintiff_more_than_three, *defendant_list, defendant_more_than_three]\n",
    "\n",
    "\n",
    "    def load_daily_docket_search():\n",
    "        driver.get('https://www.oscn.net/applications/oscn/report.asp?report=DailyFilings')\n",
    "        #wait for page to load\n",
    "        WebDriverWait(driver, long_timeout).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//div[@id=\"oscn-content\"]')))\n",
    "\n",
    "    def date_to_search(year, subtract_days):\n",
    "        global search_date\n",
    "        now = datetime.now()\n",
    "        current_year = int(now.strftime(\"%Y\"))\n",
    "        current_day = now.strftime(\"%D\")\n",
    "        two_digit_year = str(year)[-2:]\n",
    "        if current_year == year:\n",
    "            search_date = str(datetime.today() - timedelta(days=subtract_days))[0:10]\n",
    "        else:\n",
    "            if subtract_days == 1:\n",
    "                search_date = ('12/31/' + two_digit_year)\n",
    "            elif subtract_days == 2:\n",
    "                search_date = ('12/30/' + two_digit_year)\n",
    "            elif subtract_days == 3:\n",
    "                search_date = ('12/29/' + two_digit_year)\n",
    "            elif subtract_days == 4:\n",
    "                search_date = ('12/28/' + two_digit_year)\n",
    "            elif subtract_days == 5:\n",
    "                search_date = ('12/27/' + two_digit_year)\n",
    "            elif subtract_days == 6:\n",
    "                search_date = ('12/26/' + two_digit_year)\n",
    "\n",
    "    def search_last_case(search_date):\n",
    "        if clean(county) == 'oklahoma':\n",
    "            county_option = '8'\n",
    "        elif clean(county) == 'tulsa':\n",
    "            county_option = '13'\n",
    "        else:\n",
    "            print('Only Oklahoma and Tulsa counties are supported.')\n",
    "            #return\n",
    "        prefix = '//select[@name=\"db\"]/option['\n",
    "        suffix = ']'\n",
    "        xpath = (prefix + county_option + suffix)\n",
    "        driver.find_element_by_xpath(xpath).click()\n",
    "        driver.find_element_by_xpath('//input[@name=\"StartDate\"]').send_keys(search_date)\n",
    "        driver.find_element_by_xpath('//input[@type=\"SUBMIT\"]').click()\n",
    "\n",
    "    def parse_sc_table():\n",
    "        global last_case_number\n",
    "        #find small claims table\n",
    "        sc_table = driver.find_elements_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody/tr')\n",
    "        #count small claims table\n",
    "        sc_rows = len(sc_table)\n",
    "        row_prefix = '//*[contains(text(), \"SC-\")]//ancestor::tbody/tr['\n",
    "        row_suffix = ']/td[1]'\n",
    "        row_xpath = (row_prefix + str(sc_rows) + row_suffix)\n",
    "        last_case_number = driver.find_element_by_xpath(row_xpath).text\n",
    "        print(\"The last case for \" + county + \" is \" + last_case_number + ' from ' + search_date + '.')\n",
    "\n",
    "    def get_last_case_number(year, county, headless = 'no'):\n",
    "        global last_case_number\n",
    "        oklahoma.load_new_driver(county, headless = headless)\n",
    "        oklahoma.date_to_search(year, 1)\n",
    "        oklahoma.load_daily_docket_search()\n",
    "        oklahoma.search_last_case(search_date)\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody')\n",
    "            oklahoma.parse_sc_table()\n",
    "        except:\n",
    "            oklahoma.date_to_search(year, 2)\n",
    "            oklahoma.load_daily_docket_search()\n",
    "            oklahoma.search_last_case(search_date)\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody')\n",
    "                oklahoma.parse_sc_table()\n",
    "            except:\n",
    "                oklahoma.date_to_search(year, 3)\n",
    "                oklahoma.load_daily_docket_search()\n",
    "                oklahoma.search_last_case(search_date)\n",
    "                try:\n",
    "                    driver.find_element_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody')\n",
    "                    oklahoma.parse_sc_table()\n",
    "                except:\n",
    "                    oklahoma.date_to_search(year, 4)\n",
    "                    oklahoma.load_daily_docket_search()\n",
    "                    oklahoma.search_last_case(search_date)\n",
    "                    try:\n",
    "                        driver.find_element_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody')\n",
    "                        oklahoma.parse_sc_table()\n",
    "                    except:\n",
    "                        oklahoma.date_to_search(year, 5)\n",
    "                        oklahoma.load_daily_docket_search()\n",
    "                        oklahoma.search_last_case(search_date)\n",
    "                        try:\n",
    "                            driver.find_element_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody')\n",
    "                            oklahoma.parse_sc_table()\n",
    "                        except:\n",
    "                            oklahoma.date_to_search(year, 6)\n",
    "                            oklahoma.load_daily_docket_search()\n",
    "                            oklahoma.search_last_case(search_date)\n",
    "                            try:\n",
    "                                driver.find_element_by_xpath('//*[contains(text(), \"SC-\")]//ancestor::tbody')\n",
    "                                oklahoma.parse_sc_table()\n",
    "                            except:\n",
    "                                last_case_number = 'error'\n",
    "        return last_case_number\n",
    "\n",
    "\n",
    "    def scrape_cases(start, end, year, county, headless = ''):\n",
    "\n",
    "        #creating file names based on start time and date\n",
    "        global database_name, failure_name, failed_cases\n",
    "        now = datetime.now()\n",
    "        file_path = './output/'\n",
    "        database_name = (file_path + county + '-' + str(start) + '-' + str(end) + '-' + str(now.strftime(\"%D-%H-%M\")).replace('/', '-') + '.csv')\n",
    "        failure_name = (file_path + county + '-' + str(start) + '-' + str(end) + '-' + str(now.strftime(\"%D-%H-%M\")).replace('/', '-') + '-failures.txt')\n",
    "\n",
    "        # is selected county supported?\n",
    "        if clean(county) != 'tulsa' and clean(county) != 'oklahoma':\n",
    "            print('Only Tulsa and Oklahoma City are currently supported.')\n",
    "        else:\n",
    "            failed_cases = list()\n",
    "            if clean(county) == 'tulsa':\n",
    "                ok_tulsa.create_files(database_name, failure_name)\n",
    "            elif clean(county) == 'oklahoma':\n",
    "                ok_oklahoma.create_files(database_name, failure_name)\n",
    "            #load driver\n",
    "            oklahoma.load_new_driver(county, headless = headless)\n",
    "            #create list of urls\n",
    "            oklahoma.create_case_list(start, end, year, county)\n",
    "\n",
    "\n",
    "\n",
    "            # load, scrape, and write data for every case in the case_numbers list\n",
    "            for enum, i in enumerate(case_list):\n",
    "                try:\n",
    "                    # report position in loop\n",
    "                    remaining = (((len(case_list)) - 1) - enum)\n",
    "                    remaining = str(remaining)\n",
    "                    enum = str(enum + 1)\n",
    "                    print('Starting ' + enum + '. ' + remaining + ' remain.')\n",
    "\n",
    "                    #load case_details page\n",
    "                    driver.get(i)\n",
    "                    #wait for page to load\n",
    "                    WebDriverWait(driver, long_timeout).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '//div[@id=\"oscn-content\"]')))\n",
    "                    print('Case loaded.')\n",
    "\n",
    "                    #parse information on page\n",
    "\n",
    "                    ampersand_test = does_string_appear(driver.find_element_by_xpath('//table[@class=\"caseStyle\"]/tbody/tr/td').text, '&')\n",
    "                    if ampersand_test != -1:\n",
    "                        second_string = '& '\n",
    "                    else:\n",
    "                        second_string = 'AND '\n",
    "                    oklahoma.parse_parties(second_string)\n",
    "\n",
    "                    if clean(county) == 'tulsa':\n",
    "                        ok_tulsa.parse_attorneys()\n",
    "                    if clean(county) == 'oklahoma':\n",
    "                        ok_oklahoma.parse_attorneys()\n",
    "\n",
    "\n",
    "                    if clean(county) == 'tulsa':\n",
    "                        ok_tulsa.parse_case_details()\n",
    "                        ok_tulsa.write_data(database_name)\n",
    "                    if clean(county) == 'oklahoma':\n",
    "                        ok_oklahoma.parse_case_details()\n",
    "                        ok_oklahoma.write_data(database_name)\n",
    "\n",
    "                    print('Finished scraping ' + i + '.')\n",
    "                    if enum == str(len(case_list)):\n",
    "                        clear_output(wait=False)\n",
    "                        print(\"HOORAY! THE PROGRAM IS FINISHED. There were \" + str(len(failed_cases)) + \" failures.\")\n",
    "                    else:\n",
    "                        clear_output(wait=True)\n",
    "                except:\n",
    "                    #if there is a failure, this will log the case number as a failure in a new list and report in the console\n",
    "                    with open(failure_name, 'a', newline='') as outfile:\n",
    "                        writer = csv.writer(outfile, delimiter=',')\n",
    "                        writer.writerow(i)\n",
    "                    failed_cases.append(i)\n",
    "                    if enum == str(len(case_list)):\n",
    "                        print(\"The final case number resulted in an error. There have been \" + str(len(failed_cases)) + \" error(s) total.\")\n",
    "                    else:\n",
    "                        print(\"There was an error. There have been \" + str(len(failed_cases)) + \" error(s) so far. There are \" + remaining + \" loops left.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ok_tulsa():\n",
    "    def parse_attorneys():\n",
    "        global attorney_output\n",
    "        attorney_name = list()\n",
    "        attorney_bar_num = list()\n",
    "        attorney_address = list()\n",
    "        attorney_rep = list()\n",
    "\n",
    "        try:\n",
    "            attorney_table = driver.find_element_by_xpath('//th[contains(text(), \"Attorney\")]/ancestor::table')\n",
    "            attorney_rows = attorney_table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "\n",
    "            #now running the for loop to overwrite data if attorneys exist\n",
    "            for enu, z in enumerate(attorney_rows):\n",
    "                row = str(enu + 1)\n",
    "                if enu % 2 == 0:\n",
    "                    prefix = '//th[contains(text(), \"Attorney\")]/ancestor::table/tbody/tr['\n",
    "                    suffix_1 = ']/td'\n",
    "                    suffix_2 = ']/td[2]'\n",
    "                    try:\n",
    "                        attorney_list = driver.find_element_by_xpath(prefix + row + suffix_1).text.splitlines()\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        attorney_list_two = attorney_list[0].split(\" (\")\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        attorney_name.append(clean(attorney_list_two[0]).replace('  ', ' '))\n",
    "                    except:\n",
    "                        attorney_name.append('none')\n",
    "                    try:\n",
    "                        attorney_bar_num.append(clean(attorney_list_two[1]).replace('bar #', '').replace(')', ''))\n",
    "                    except:\n",
    "                        attorney_bar_num.append('none')\n",
    "                    try:\n",
    "                        attorney_address.append(clean(attorney_list[1]) + ' ' + clean(attorney_list[2]))\n",
    "                    except:\n",
    "                        attorney_address.append('none')\n",
    "                    try:\n",
    "                        attorney_rep.append(clean(driver.find_element_by_xpath(prefix + row + suffix_2).text).replace(',', ''))\n",
    "                    except:\n",
    "                        attorney_rep.append('none')\n",
    "                else:\n",
    "                    pass\n",
    "        except:\n",
    "            attorney_name.append('none')\n",
    "            attorney_bar_num.append('none')\n",
    "            attorney_address.append('none')\n",
    "            attorney_rep.append('none')\n",
    "\n",
    "        parse_party_list(attorney_name)\n",
    "        parse_party_list(attorney_bar_num)\n",
    "        parse_party_list(attorney_address)\n",
    "        parse_party_list(attorney_rep)\n",
    "        attorney_more_than_three = more_than_three(attorney_name)\n",
    "        attorney_output = [attorney_name[0], attorney_bar_num[0], attorney_address[0], attorney_rep[0],\n",
    "                        attorney_name[1], attorney_bar_num[1], attorney_address[1], attorney_rep[1],\n",
    "                        attorney_name[2], attorney_bar_num[2], attorney_address[2], attorney_rep[2],\n",
    "                        attorney_more_than_three]\n",
    "\n",
    "    # this function parses a Tulsa case details page\n",
    "    def parse_case_details():\n",
    "\n",
    "        global case_details\n",
    "        case_details = list()\n",
    "        case_type_list = (driver.find_element_by_xpath('//table[@class=\"caseStyle\"]/tbody/tr/td[2]').text).split('\\n')\n",
    "        case_number = clean(case_type_list[0]).replace('no. ', '')\n",
    "        case_type = clean(case_type_list[1]).replace('small claims: ', '').replace('(', \"\").replace(')', '')\n",
    "        try:\n",
    "            file_date = get_date(try_assign('//td[contains(text(), \"Filed:\")]').split('filed')[1].replace(': ', ''))\n",
    "        except:\n",
    "            file_date = 'none'\n",
    "        try:\n",
    "            closed_date = get_date(try_assign('//td[contains(text(), \"Filed:\")]').split('closed')[1].replace(': ', ''))\n",
    "        except:\n",
    "            closed_date = 'none'\n",
    "        writ_to_marshall = get_date(try_assign(\"//*[contains(text(), 'EXECUTION ISSUED')]/ancestor::tr\"))\n",
    "        writ_executed = try_assign(\"//*[contains(text(), 'EXECUTION RETURNED')]\").replace('execution returned per writ ', '')\n",
    "        amount_owed = try_assign(\"//*[contains(text(), 'AMOUNT IN DEBT')]\").replace('amount in debt of ', '').replace('$', '').replace('<....>', '')\n",
    "        judge = try_assign('//th[contains(text(), \"Docket\")]/ancestor::table/tbody/tr/td[3]')\n",
    "        ao_2020_5_order = try_assign('//*[contains(text(), \"AO-2020-5\")]')\n",
    "        cares_act = get_date(try_assign('//*[contains(text(), \"CARES ACT\")]/ancestor::tr'))\n",
    "        payor = clean(parse_string(try_assign('//table[@class=\"docketlist\"]//*[contains(text(), \"RECEIPT\")]'), \"payor:\", \"paid:\").replace('total amount', ''))\n",
    "        try:\n",
    "            disposition_list = driver.find_element_by_xpath('//*[contains(text(), \"Disposition Information\")]/ancestor::table/tbody/tr/td[3]').text.replace('Disposed: ', '').split(', ')\n",
    "            try:\n",
    "                #this line looks for settlements in disposition\n",
    "                driver.find_element_by_xpath('//table[contains(text(), \"Settled\")]')\n",
    "                disposition = 'settled'\n",
    "            except:\n",
    "                #otherwise it pulls the official finding at the beginning of the string\n",
    "                disposition = clean(disposition_list[0])\n",
    "            disposition_date = clean(disposition_list[1])[0:10]\n",
    "        except:\n",
    "            disposition = 'none'\n",
    "            disposition_date = 'none'\n",
    "        disposition_note = try_assign('//nobr[contains(text(), \"DISP\")]//ancestor::tr/td[3]')\n",
    "        plaintiff_appeared = parse_string(disposition_note, 'plaintiff', '.')\n",
    "        defendant_appeared = parse_string(disposition_note, 'defendant', '.')\n",
    "        try:\n",
    "            possession_test = disposition_note.find('possession of the premises')\n",
    "            if possession_test == -1:\n",
    "                possession_test_two = disposition_note.find('possession of property')\n",
    "                if possession_test_two == -1:\n",
    "                    possession_of_premises = 'no'\n",
    "                else:\n",
    "                    possession_of_premises = 'yes'\n",
    "            else:\n",
    "                possession_of_premises = 'yes'\n",
    "        except:\n",
    "            possession_of_premises = 'no'\n",
    "        court_costs_awarded = does_string_appear(disposition_note, 'court costs against the named defendant')\n",
    "        possession_only = does_string_appear(disposition_note, 'possession only')\n",
    "        docket_len = len(driver.find_elements_by_xpath('//th[contains(text(), \"Description\")]/ancestor::table/tbody/tr'))\n",
    "        docket_prefix = '//th[contains(text(), \"Description\")]/ancestor::table/tbody/tr['\n",
    "        docket_desc_suffix = ']/td[3]'\n",
    "        docket_date_suffix = ']/td[1]'\n",
    "        last_action = clean(driver.find_element_by_xpath(docket_prefix + str(docket_len) + docket_desc_suffix).text)\n",
    "        last_action_date = clean(driver.find_element_by_xpath(docket_prefix + str(docket_len) + docket_date_suffix).text)\n",
    "        now = datetime.now()\n",
    "        last_scrape = now.strftime(\"%D-%H:%M\")\n",
    "        case_details = [case_number, case_type, file_date, closed_date, writ_to_marshall, writ_executed, amount_owed, judge, disposition, disposition_date, disposition_note, plaintiff_appeared, defendant_appeared, possession_of_premises, court_costs_awarded, possession_only, payor, cares_act, ao_2020_5_order, docket_len, last_action, last_action_date, last_scrape]\n",
    "\n",
    "    # this function creates a database and failure log with county-specific header\n",
    "    def create_files(database_name, failure_name):\n",
    "        header = ['case_number', 'case_type', 'file_date', 'closed_date', 'writ_to_marshall', 'writ_executed', 'amount_owed', 'judge', 'disposition', 'disposition_date', 'disposition_note', 'plaintiff_appeared', 'defendant_appeared', 'possesion_of_premises', 'court_costs_awarded', 'possession_only', 'payor', 'cares_act', 'ao_2020_5_order', 'docket_len', 'last_action', 'last_action_date', 'last_scrape', 'attorney_one', 'attorney_one_bar_num', 'attorney_one_address', 'attorney_one_rep', 'attorney_two', 'attorney_two_bar_num', 'attorney_two_address', 'attorney_two_rep', 'attorney_three', 'attorney_three_bar_num', 'attorney_three_address', 'attorney_three_rep', 'attorney_more_than_three', 'plaintiff_one', 'plaintiff_two', 'plaintiff_three', 'plaintiff_more_than_three', 'defendant_one', 'defendant_two', 'defendant_three', 'defendant_more_than_three']\n",
    "        create_dataframe(database_name, header)\n",
    "        create_failure_log(failure_name)\n",
    "\n",
    "    # this function writes to a given database with county-specific output\n",
    "    def write_data(database_name):\n",
    "        with open(database_name, 'a', newline='') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=',')\n",
    "            data_out = [*case_details, *attorney_output, *party_output]\n",
    "            writer.writerow(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOORAY! THE PROGRAM IS FINISHED. There were 0 failures.\n"
     ]
    }
   ],
   "source": [
    "oklahoma.scrape_cases(1, 2, 2019, 'tulsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oklahoma.get_last_case_number(2019, 'tulsa')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
